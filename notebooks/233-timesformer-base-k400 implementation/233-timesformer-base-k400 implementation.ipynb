{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert and Optimize TimeSformer with OpenVINO™\n",
    "TimeSformer(from Time-Space Transformer) devised and proposed in [Is Space-Time Attention All You Need for Video Understanding?](https://arxiv.org/abs/2102.05095) uses self-attention layers and feedforward layers to extract features from frames. The main innovation here is the use of a modality called \"pose\" which refers to the spatial location and orientation of an object in video. By incorporating this information,TimeSformer is able to keep track of fine-grained details of activity of objects in the video. \n",
    "\n",
    "The variation of model that we will be using is the base model trained on kinetics400 dataset. The compiled model in available at [hugging face](https://huggingface.co/facebook/timesformer-base-finetuned-k400)\n",
    "\n",
    "The tutorial consists of the following steps:\n",
    "- Validate the original model\n",
    "- Convert PyTorch model to OpenVINO IR\n",
    "- Validate converted model\n",
    "- Prepare and run optimization pipeline\n",
    "- Compare performance of the FP32 and quantized models.\n",
    "- Compare accuracy of the FP32 and quantized models."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validating the Original Model\n",
    "\n",
    "The first step involves downloading and running the pretrained model on test data from kinetics400 dataset since this was the dataset the model was trained on, one can expect the model to perform well since it was trained on this dataset, the model is available on hugging face and can be downloaded directly from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first step involves downloading the model, while one can also use wget and torch.load method to load the model, \n",
    "#we can also use TimesformerForVideoClassification method since our aim is to mainly demonstrate model performance\n",
    "from transformers import TimesformerForVideoClassification\n",
    "model = TimesformerForVideoClassification.from_pretrained(\"facebook/timesformer-base-finetuned-k400\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to prepare the data preprocessing pipeline, once again this can be done using transforms.Compose but instead we will be using AutoImageProcessor from transforms to take care of this for us, more about this method [here](https://huggingface.co/docs/transformers/v4.26.1/en/autoclass_tutorial) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor\n",
    "processor = AutoImageProcessor.from_pretrained(\"facebook/timesformer-base-finetuned-k400\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time time to load the test split of the kinetics 400 dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\saksh\\anaconda3\\envs\\py37\\lib\\site-packages (2.28.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\saksh\\anaconda3\\envs\\py37\\lib\\site-packages (from requests) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\saksh\\anaconda3\\envs\\py37\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\saksh\\anaconda3\\envs\\py37\\lib\\site-packages (from requests) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\saksh\\anaconda3\\envs\\py37\\lib\\site-packages (from requests) (3.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests\n",
    "import requests\n",
    "url  = \"https://storage.googleapis.com/deepmind-media/Datasets/kinetics400.tar.gz\"\n",
    "r = requests.get(url)\n",
    "with open('kinetics400.tar.gz','wb') as f:\n",
    "    f.write(r.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now to unzip the file\n",
    "import tarfile\n",
    "file = tarfile.open('kinetics400.tar.gz')\n",
    "file.extractall('./')\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test_dataset = pd.read_csv('./kinetics400/test.csv').drop(columns='split',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>youtube_id</th>\n",
       "      <th>time_start</th>\n",
       "      <th>time_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>drinking beer</td>\n",
       "      <td>--6bJUbfpnQ</td>\n",
       "      <td>17</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>climbing tree</td>\n",
       "      <td>--8YXc8iCt8</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>surfing water</td>\n",
       "      <td>--coBvtS-eQ</td>\n",
       "      <td>57</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stomping grapes</td>\n",
       "      <td>--q6ElFyVq0</td>\n",
       "      <td>148</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tai chi</td>\n",
       "      <td>--q_mvQ8zP8</td>\n",
       "      <td>67</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34746</th>\n",
       "      <td>catching or throwing softball</td>\n",
       "      <td>zzHsdlYe_5I</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34747</th>\n",
       "      <td>skiing (not slalom or crosscountry)</td>\n",
       "      <td>zzl-3zkieiE</td>\n",
       "      <td>436</td>\n",
       "      <td>446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34748</th>\n",
       "      <td>jumping into pool</td>\n",
       "      <td>zzpqbqLllzA</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34749</th>\n",
       "      <td>gargling</td>\n",
       "      <td>zzy_artj1B8</td>\n",
       "      <td>210</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34750</th>\n",
       "      <td>juggling fire</td>\n",
       "      <td>zzzkS3amkWE</td>\n",
       "      <td>124</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34751 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     label   youtube_id  time_start  time_end\n",
       "0                            drinking beer  --6bJUbfpnQ          17        27\n",
       "1                            climbing tree  --8YXc8iCt8           2        12\n",
       "2                            surfing water  --coBvtS-eQ          57        67\n",
       "3                          stomping grapes  --q6ElFyVq0         148       158\n",
       "4                                  tai chi  --q_mvQ8zP8          67        77\n",
       "...                                    ...          ...         ...       ...\n",
       "34746        catching or throwing softball  zzHsdlYe_5I          11        21\n",
       "34747  skiing (not slalom or crosscountry)  zzl-3zkieiE         436       446\n",
       "34748                    jumping into pool  zzpqbqLllzA           1        11\n",
       "34749                             gargling  zzy_artj1B8         210       220\n",
       "34750                        juggling fire  zzzkS3amkWE         124       134\n",
       "\n",
       "[34751 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the dataset is up and loaded nicely, we have to create a function that will automatically download these vidoes from the selected time and preprocess and send it to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aa721c0b0227924e1313fb54ae915d2c7d3543290c470868f96f7f07b40b2667"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
